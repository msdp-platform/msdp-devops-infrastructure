# NOTE: Config-driven workflow. Values are read from
# - infrastructure/config/globals.yaml (global defaults)
# - config/envs/<env>.yaml (environment specifics)
# Only input is action; no interactive network inputs.
name: azure-network
on:
  push:
    branches: [main]
    paths:
      - "infrastructure/environment/azure/network/**"
      - "config/**"
      - "infrastructure/config/**" # include if globals live here
  workflow_dispatch:
    inputs:
      action:
        description: plan | apply | destroy
        required: true
        default: plan
        type: choice
        options: [plan, apply, destroy]
      size:
        description: Optional subnet size override (large|medium|small)
        required: false
        default: ""

permissions:
  id-token: write
  contents: read

env:
  TF_INPUT: "false"
  ARM_USE_OIDC: "true"

jobs:
  apply:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      # Azure OIDC (for azurerm provider)
      - name: Azure login (OIDC)
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Export ARM env
        run: |
          echo "ARM_CLIENT_ID=${{ secrets.AZURE_CLIENT_ID }}" >> $GITHUB_ENV
          echo "ARM_TENANT_ID=${{ secrets.AZURE_TENANT_ID }}" >> $GITHUB_ENV
          echo "ARM_SUBSCRIPTION_ID=${{ secrets.AZURE_SUBSCRIPTION_ID }}" >> $GITHUB_ENV

      # AWS OIDC (for S3/DynamoDB backend)
      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: eu-west-1

      - name: Bootstrap environment
        uses: ./.github/actions/bootstrap-env
        with:
          env: dev

      # --- BACKEND: create/ensure S3+DDB and write backend-config.json ---
      - name: Terraform Backend (AWS)
        uses: ./.github/actions/terraform-backend
        with:
          repo-shortname: infra
          project: msdp
          env: dev
          cloud: aws
          cloud-segment: azure # key path segment; keeps state per cloud segment
          app: network # stack name
          function: tfstate
          key-salt: infrastructure/environment/azure/network
          aws-region: eu-west-1
          # optional: pipeline-name: custom-name-here
          # optional: allow-key-mutation: "false"
          use-shared-lock-table: "true"
          # optional: lock-table-name:

      # --- INIT using the generated backend-config.json (safe) ---
      - name: Terraform Init (Reusable)
        uses: ./.github/actions/terraform-init
        with:
          working-directory: infrastructure/environment/azure/network
          terraform-version: 1.13.2
          backend-config-file: ${{ env.TF_BACKEND_CONFIG_FILE }}

      - name: Show backend state key
        shell: bash
        run: |
          set -euo pipefail
          CONFIG="${{ env.TF_BACKEND_CONFIG_FILE }}"
          if [ -f "$CONFIG" ]; then
            echo "Backend state key: $(jq -r '.key' "$CONFIG")"
          else
            echo "Backend config file not found: $CONFIG" >&2
          fi

      - name: Build network.auto.tfvars.json (from config)
        working-directory: infrastructure/environment/azure/network
        shell: bash
        run: |
          set -euo pipefail
          CFG_GLOBAL="${TF_VAR_global_config_path:-infrastructure/config/globals.yaml}"
          CFG_ENV="${TF_VAR_env_config_path:-config/envs/dev.yaml}"
          get_yaml() {
            local file="$1" key="$2"
            if command -v yq >/dev/null 2>&1; then
              yq -r "$key" "$file" 2>/dev/null || true
            else
              grep -E "^\s*${key//./\\.}\s*:\s*" "$file" | head -n1 | sed 's/.*:\s*//' | tr -d '"' | tr -d "'" || true
            fi
          }
          cfg_loc=$(get_yaml "$CFG_GLOBAL" '.azure.location')
          cfg_rg=$(get_yaml "$CFG_ENV" '.azure.resourceGroup')
          cfg_vnet=$(get_yaml "$CFG_ENV" '.azure.vnetName')
          cfg_vnet_cidr=$(get_yaml "$CFG_ENV" '.azure.vnetCidr')
          # Try multi-cluster spec from azure.aksClusters; fallback to single-subnet config
          clusters_json="{}"
          if command -v yq >/dev/null 2>&1; then
            clusters_json=$(yq -r '.azure.aksClusters // {}' "$CFG_ENV")
          fi
          addrs=$(jq -nc --arg cidr "$cfg_vnet_cidr" '$cidr|[.]')
          # Normalize clusters to array of {name, subnetName, size}
          clusters_arr=$(jq -c 'if type=="object" then [ to_entries[] | {name: .key, subnetName: (.value.subnetName // ("snet-" + .key)), size: (.value.size // "medium")} ] elif type=="array" then [ .[] | {name: .name, subnetName: (.subnetName // ("snet-" + .name)), size: (.size // "medium")} ] else [] end' <<< "$clusters_json")
          if [ "$(jq -r 'length' <<< "$clusters_arr")" -gt 0 ]; then
            # Map size label to newbits
            map_size() { case "$1" in large) echo 8;; medium) echo 9;; small) echo 10;; *) echo 9;; esac }
            # Build computed_subnets_spec from clusters
            spec='[]'
            for row in $(echo "$clusters_arr" | jq -c '.[]'); do
              sname=$(echo "$row" | jq -r '.subnetName')
              # Apply pipeline size override if provided
              size_in='${{ github.event.inputs.size || '' }}'
              if [ -n "$size_in" ]; then
                size="$size_in"
              else
                size=$(echo "$row" | jq -r '.size')
              fi
              nb=$(map_size "$size")
              spec=$(jq -nc --argjson cur "$spec" --arg n "$sname" --argjson nb "$nb" '$cur + [{name:$n,newbits:$nb}]')
            done
            jq -n --arg rg "$cfg_rg" --arg loc "$cfg_loc" --arg vnet "$cfg_vnet" \
                  --arg base "$cfg_vnet_cidr" --argjson spec "$spec" \
                  '{resource_group:$rg, location:$loc, vnet_name:$vnet, base_cidr:$base, computed_subnets_spec:$spec}' \
              > network.auto.tfvars.json
            echo "Wrote $(pwd)/network.auto.tfvars.json (computed_subnets_spec from aksClusters)"
          else
            cfg_subnet=$(get_yaml "$CFG_ENV" '.azure.subnetName')
            cfg_subnet_cidr=$(get_yaml "$CFG_ENV" '.azure.subnetCidr')
            if [ -z "${cfg_rg:-}" ] || [ -z "${cfg_loc:-}" ] || [ -z "${cfg_vnet:-}" ] || [ -z "${cfg_vnet_cidr:-}" ] || [ -z "${cfg_subnet:-}" ] || [ -z "${cfg_subnet_cidr:-}" ]; then
              echo "::error ::Missing required config values for network (resourceGroup, location, vnetName, vnetCidr, subnetName, subnetCidr)."; exit 1
            fi
            subnets=$(jq -nc --arg name "$cfg_subnet" --arg cidr "$cfg_subnet_cidr" '[{name:$name,cidr:$cidr}]')
            jq -n --arg rg "$cfg_rg" --arg loc "$cfg_loc" --arg vnet "$cfg_vnet" \
                  --argjson address_space "$addrs" --argjson subnets "$subnets" \
                  '{resource_group:$rg, location:$loc, vnet_name:$vnet, address_space:$address_space, subnets:$subnets}' \
              > network.auto.tfvars.json
            echo "Wrote $(pwd)/network.auto.tfvars.json (single subnet)"
          fi

      - name: Terraform plan
        if: ${{ github.event_name != 'workflow_dispatch' || github.event.inputs.action == 'plan' || github.event.inputs.action == 'apply' }}
        working-directory: infrastructure/environment/azure/network
        run: terraform plan -out=tfplan

      - name: Terraform apply
        if: ${{ (github.event_name != 'workflow_dispatch' && github.ref == 'refs/heads/main' && github.event_name != 'pull_request') || github.event.inputs.action == 'apply' }}
        working-directory: infrastructure/environment/azure/network
        run: terraform apply -auto-approve tfplan || { terraform plan -out=tfplan && terraform apply -auto-approve tfplan; }

      - name: Terraform destroy
        if: ${{ github.event.inputs.action == 'destroy' }}
        working-directory: infrastructure/environment/azure/network
        run: terraform destroy -auto-approve
