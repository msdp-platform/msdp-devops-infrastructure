name: ğŸš€ Unified Deploy - Smart & Complete Pipeline

on:
  push:
    branches: [dev, test, prod]
    paths:
      - "infrastructure/**"
      - ".github/workflows/deploy-unified.yml"
  pull_request:
    branches: [test, prod]
    paths:
      - "infrastructure/**"
  workflow_dispatch:
    inputs:
      environment:
        description: "Environment to deploy"
        required: true
        default: "dev"
        type: choice
        options:
          - dev
          - test
          - prod
      deploy_platform:
        description: "Deploy platform components"
        required: false
        default: true
        type: boolean
      deploy_applications:
        description: "Deploy applications"
        required: false
        default: true
        type: boolean
      force_deploy:
        description: "Force deployment even if versions match"
        required: false
        default: false
        type: boolean
      dry_run:
        description: "Perform dry run"
        required: false
        default: false
        type: boolean

env:
  AZURE_CLIENT_ID: 129dd1fb-3d94-4e10-b451-2b0dea64daee
  AZURE_TENANT_ID: a4474822-c84f-4bd1-bc35-baed17234c9f
  AZURE_SUBSCRIPTION_ID: ecd977ed-b8df-4eb6-9cba-98397e1b2491
  AWS_ROLE_ARN: ${{ secrets.AWS_ROLE_ARN }}
  AWS_REGION: us-east-1

jobs:
  detect-environment:
    runs-on: ubuntu-latest
    outputs:
      environment: ${{ steps.detect.outputs.environment }}
      cluster_name: ${{ steps.detect.outputs.cluster_name }}
      resource_group: ${{ steps.detect.outputs.resource_group }}
      should_deploy: ${{ steps.detect.outputs.should_deploy }}
    steps:
      - name: Detect Environment
        id: detect
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            ENVIRONMENT="${{ github.event.inputs.environment }}"
          else
            case "${{ github.ref_name }}" in
              dev) ENVIRONMENT="dev" ;;
              test) ENVIRONMENT="test" ;;
              prod) ENVIRONMENT="prod" ;;
              *) ENVIRONMENT="dev" ;;
            esac
          fi

          case "$ENVIRONMENT" in
            dev)
              CLUSTER_NAME="msdp-infra-aks"
              RESOURCE_GROUP="delivery-platform-aks-rg"
              ;;
            test)
              CLUSTER_NAME="msdp-infra-aks-test"
              RESOURCE_GROUP="delivery-platform-aks-rg-test"
              ;;
            prod)
              CLUSTER_NAME="msdp-infra-aks-prod"
              RESOURCE_GROUP="delivery-platform-aks-rg-prod"
              ;;
          esac

          echo "environment=$ENVIRONMENT" >> $GITHUB_OUTPUT
          echo "cluster_name=$CLUSTER_NAME" >> $GITHUB_OUTPUT
          echo "resource_group=$RESOURCE_GROUP" >> $GITHUB_OUTPUT
          echo "should_deploy=true" >> $GITHUB_OUTPUT

  check-component-versions:
    needs: detect-environment
    if: needs.detect-environment.outputs.should_deploy == 'true' && (github.event.inputs.deploy_platform == 'true' || github.event.inputs.deploy_platform == null)
    runs-on: ubuntu-latest
    environment: ${{ needs.detect-environment.outputs.environment }}
    permissions:
      id-token: write
      contents: read
    outputs:
      deploy_platform: ${{ steps.versions.outputs.deploy_platform }}
      deploy_applications: ${{ steps.versions.outputs.deploy_applications }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Login to Azure
        uses: azure/login@v2
        with:
          client-id: ${{ env.AZURE_CLIENT_ID }}
          tenant-id: ${{ env.AZURE_TENANT_ID }}
          subscription-id: ${{ env.AZURE_SUBSCRIPTION_ID }}

      - name: Get AKS credentials
        run: |
          az aks get-credentials \
            --resource-group ${{ needs.detect-environment.outputs.resource_group }} \
            --name ${{ needs.detect-environment.outputs.cluster_name }} \
            --overwrite-existing

      - name: Check Component Versions
        id: versions
        run: |
          echo "ğŸ” Checking component versions..."

          # Load configuration from global.yaml
          source scripts/load-config-robust.sh
          load_global_config

          # Get expected versions from configuration
          EXPECTED_ARGOCD_VERSION=$(get_config_value "applications.argocd.version")
          EXPECTED_GRAFANA_VERSION=$(get_config_value "platform_components.grafana.version")
          EXPECTED_CROSSPLANE_VERSION=$(get_config_value "applications.crossplane.version")
          EXPECTED_BACKSTAGE_VERSION=$(get_config_value "applications.backstage.version")
          EXPECTED_CERT_MANAGER_VERSION=$(get_config_value "platform_components.cert_manager.version")
          EXPECTED_NGINX_VERSION=$(get_config_value "platform_components.nginx_ingress.version")
          EXPECTED_EXTERNAL_DNS_VERSION=$(get_config_value "platform_components.external_dns.version")
          EXPECTED_PROMETHEUS_VERSION=$(get_config_value "platform_components.prometheus.version")

          echo "ğŸ“‹ Expected versions from configuration:"
          echo "  ArgoCD: $EXPECTED_ARGOCD_VERSION"
          echo "  Grafana: $EXPECTED_GRAFANA_VERSION"
          echo "  Crossplane: $EXPECTED_CROSSPLANE_VERSION"
          echo "  Backstage: $EXPECTED_BACKSTAGE_VERSION"
          echo "  Cert-Manager: $EXPECTED_CERT_MANAGER_VERSION"
          echo "  NGINX Ingress: $EXPECTED_NGINX_VERSION"
          echo "  External DNS: $EXPECTED_EXTERNAL_DNS_VERSION"
          echo "  Prometheus: $EXPECTED_PROMETHEUS_VERSION"

          DEPLOY_PLATFORM="false"
          DEPLOY_APPLICATIONS="false"

          # Function to normalize version strings for comparison
          normalize_version() {
            echo "$1" | sed 's/^v//' | sed 's/[^0-9.]//g'
          }

          # Check if components exist and get versions
          if kubectl get deployment -n argocd argocd-server >/dev/null 2>&1; then
            CURRENT_ARGOCD=$(kubectl get deployment -n argocd argocd-server -o jsonpath='{.spec.template.spec.containers[0].image}' | grep -o 'v[0-9]\+\.[0-9]\+\.[0-9]\+' || echo "unknown")
            echo "ArgoCD: Current=$CURRENT_ARGOCD, Expected=$EXPECTED_ARGOCD_VERSION"
            if [ "$CURRENT_ARGOCD" != "$EXPECTED_ARGOCD_VERSION" ] || [ "${{ github.event.inputs.force_deploy }}" = "true" ]; then
              echo "  âš ï¸  Version mismatch detected - will deploy"
              DEPLOY_APPLICATIONS="true"
            else
              echo "  âœ… Version matches - skipping deployment"
            fi
          else
            echo "ArgoCD not found, will deploy"
            DEPLOY_APPLICATIONS="true"
          fi

          if kubectl get deployment -n monitoring grafana >/dev/null 2>&1; then
            CURRENT_GRAFANA=$(kubectl get deployment -n monitoring grafana -o jsonpath='{.spec.template.spec.containers[0].image}' | grep -o '[0-9]\+\.[0-9]\+\.[0-9]\+' || echo "unknown")
            echo "Grafana: Current=$CURRENT_GRAFANA, Expected=$EXPECTED_GRAFANA_VERSION"
            if [ "$CURRENT_GRAFANA" != "$EXPECTED_GRAFANA_VERSION" ] || [ "${{ github.event.inputs.force_deploy }}" = "true" ]; then
              echo "  âš ï¸  Version mismatch detected - will deploy"
              DEPLOY_PLATFORM="true"
            else
              echo "  âœ… Version matches - skipping deployment"
            fi
          else
            echo "Grafana not found, will deploy"
            DEPLOY_PLATFORM="true"
          fi

          if kubectl get deployment -n crossplane-system crossplane >/dev/null 2>&1; then
            CURRENT_CROSSPLANE=$(kubectl get deployment -n crossplane-system crossplane -o jsonpath='{.spec.template.spec.containers[0].image}' | grep -o 'v[0-9]\+\.[0-9]\+\.[0-9]\+' || echo "unknown")
            echo "Crossplane: Current=$CURRENT_CROSSPLANE, Expected=$EXPECTED_CROSSPLANE_VERSION"
            if [ "$CURRENT_CROSSPLANE" != "$EXPECTED_CROSSPLANE_VERSION" ] || [ "${{ github.event.inputs.force_deploy }}" = "true" ]; then
              echo "  âš ï¸  Version mismatch detected - will deploy"
              DEPLOY_APPLICATIONS="true"
            else
              echo "  âœ… Version matches - skipping deployment"
            fi
          else
            echo "Crossplane not found, will deploy"
            DEPLOY_APPLICATIONS="true"
          fi

          if kubectl get deployment -n backstage backstage >/dev/null 2>&1; then
            CURRENT_BACKSTAGE=$(kubectl get deployment -n backstage backstage -o jsonpath='{.spec.template.spec.containers[0].image}' | grep -o '[0-9]\+\.[0-9]\+\.[0-9]\+' || echo "unknown")
            echo "Backstage: Current=$CURRENT_BACKSTAGE, Expected=$EXPECTED_BACKSTAGE_VERSION"
            if [ "$CURRENT_BACKSTAGE" != "$EXPECTED_BACKSTAGE_VERSION" ] || [ "${{ github.event.inputs.force_deploy }}" = "true" ]; then
              echo "  âš ï¸  Version mismatch detected - will deploy"
              DEPLOY_APPLICATIONS="true"
            else
              echo "  âœ… Version matches - skipping deployment"
            fi
          else
            echo "Backstage not found, will deploy"
            DEPLOY_APPLICATIONS="true"
          fi

          # Check platform components
          if kubectl get deployment -n ingress-nginx ingress-nginx-controller >/dev/null 2>&1; then
            CURRENT_NGINX=$(kubectl get deployment -n ingress-nginx ingress-nginx-controller -o jsonpath='{.spec.template.spec.containers[0].image}' | grep -o 'v\?[0-9]\+\.[0-9]\+\.[0-9]\+' || echo "unknown")
            NORMALIZED_CURRENT_NGINX=$(normalize_version "$CURRENT_NGINX")
            NORMALIZED_EXPECTED_NGINX=$(normalize_version "$EXPECTED_NGINX_VERSION")
            echo "NGINX Ingress: Current=$CURRENT_NGINX, Expected=$EXPECTED_NGINX_VERSION"
            if [ "$NORMALIZED_CURRENT_NGINX" != "$NORMALIZED_EXPECTED_NGINX" ] || [ "${{ github.event.inputs.force_deploy }}" = "true" ]; then
              echo "  âš ï¸  Version mismatch detected - will deploy"
              DEPLOY_PLATFORM="true"
            else
              echo "  âœ… Version matches - skipping deployment"
            fi
          else
            echo "NGINX Ingress not found, will deploy"
            DEPLOY_PLATFORM="true"
          fi

          if kubectl get deployment -n cert-manager cert-manager >/dev/null 2>&1; then
            CURRENT_CERT_MANAGER=$(kubectl get deployment -n cert-manager cert-manager -o jsonpath='{.spec.template.spec.containers[0].image}' | grep -o 'v[0-9]\+\.[0-9]\+\.[0-9]\+' || echo "unknown")
            echo "Cert-Manager: Current=$CURRENT_CERT_MANAGER, Expected=$EXPECTED_CERT_MANAGER_VERSION"
            if [ "$CURRENT_CERT_MANAGER" != "$EXPECTED_CERT_MANAGER_VERSION" ] || [ "${{ github.event.inputs.force_deploy }}" = "true" ]; then
              echo "  âš ï¸  Version mismatch detected - will deploy"
              DEPLOY_PLATFORM="true"
            else
              echo "  âœ… Version matches - skipping deployment"
            fi
          else
            echo "Cert-Manager not found, will deploy"
            DEPLOY_PLATFORM="true"
          fi

          if kubectl get deployment -n external-dns external-dns >/dev/null 2>&1; then
            CURRENT_EXTERNAL_DNS=$(kubectl get deployment -n external-dns external-dns -o jsonpath='{.spec.template.spec.containers[0].image}' | grep -o 'v[0-9]\+\.[0-9]\+\.[0-9]\+' || echo "unknown")
            echo "External DNS: Current=$CURRENT_EXTERNAL_DNS, Expected=$EXPECTED_EXTERNAL_DNS_VERSION"
            if [ "$CURRENT_EXTERNAL_DNS" != "$EXPECTED_EXTERNAL_DNS_VERSION" ] || [ "${{ github.event.inputs.force_deploy }}" = "true" ]; then
              echo "  âš ï¸  Version mismatch detected - will deploy"
              DEPLOY_PLATFORM="true"
            else
              echo "  âœ… Version matches - skipping deployment"
            fi
          else
            echo "External DNS not found, will deploy"
            DEPLOY_PLATFORM="true"
          fi

          if kubectl get deployment -n monitoring prometheus-server >/dev/null 2>&1; then
            CURRENT_PROMETHEUS=$(kubectl get deployment -n monitoring prometheus-server -o jsonpath='{.spec.template.spec.containers[0].image}' | grep -o 'v\?[0-9]\+\.[0-9]\+\.[0-9]\+' || echo "unknown")
            NORMALIZED_CURRENT_PROMETHEUS=$(normalize_version "$CURRENT_PROMETHEUS")
            NORMALIZED_EXPECTED_PROMETHEUS=$(normalize_version "$EXPECTED_PROMETHEUS_VERSION")
            echo "Prometheus: Current=$CURRENT_PROMETHEUS, Expected=$EXPECTED_PROMETHEUS_VERSION"
            if [ "$NORMALIZED_CURRENT_PROMETHEUS" != "$NORMALIZED_EXPECTED_PROMETHEUS" ] || [ "${{ github.event.inputs.force_deploy }}" = "true" ]; then
              echo "  âš ï¸  Version mismatch detected - will deploy"
              DEPLOY_PLATFORM="true"
            else
              echo "  âœ… Version matches - skipping deployment"
            fi
          else
            echo "Prometheus not found, will deploy"
            DEPLOY_PLATFORM="true"
          fi

          echo "deploy_platform=$DEPLOY_PLATFORM" >> $GITHUB_OUTPUT
          echo "deploy_applications=$DEPLOY_APPLICATIONS" >> $GITHUB_OUTPUT

          echo "ğŸ“Š Deployment Decision:"
          echo "  Platform Components: $DEPLOY_PLATFORM"
          echo "  Applications: $DEPLOY_APPLICATIONS"

  deploy-platform-components:
    needs: [detect-environment, check-component-versions]
    if: needs.detect-environment.outputs.should_deploy == 'true' && (needs.check-component-versions.outputs.deploy_platform == 'true' || github.event.inputs.force_deploy == 'true')
    runs-on: ubuntu-latest
    environment: ${{ needs.detect-environment.outputs.environment }}
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Login to Azure
        uses: azure/login@v2
        with:
          client-id: ${{ env.AZURE_CLIENT_ID }}
          tenant-id: ${{ env.AZURE_TENANT_ID }}
          subscription-id: ${{ env.AZURE_SUBSCRIPTION_ID }}

      - name: Get AKS credentials
        run: |
          az aks get-credentials \
            --resource-group ${{ needs.detect-environment.outputs.resource_group }} \
            --name ${{ needs.detect-environment.outputs.cluster_name }} \
            --overwrite-existing

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ env.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Kubernetes tools
        uses: azure/setup-kubectl@v3

      - name: Setup Helm
        uses: azure/setup-helm@v3

      - name: Setup Kustomize with Helm support
        run: |
          # Install kustomize using direct download
          cd /tmp
          rm -f kustomize
          curl -L "https://github.com/kubernetes-sigs/kustomize/releases/download/kustomize%2Fv5.0.0/kustomize_v5.0.0_linux_amd64.tar.gz" | tar xz
          sudo mv kustomize /usr/local/bin/
          # Verify installation
          kustomize version

      - name: Update Component Versions Dynamically
        run: |
          echo "ğŸ”„ Updating component versions from global configuration..."
          ./scripts/update-component-versions.sh

      - name: Clean up existing Platform Components
        if: github.event.inputs.dry_run != 'true'
        run: |
          echo "ğŸ§¹ Cleaning up existing platform components to avoid immutable field conflicts..."

          # Clean up NGINX Ingress Controller
          echo "ğŸ—‘ï¸ Cleaning up NGINX Ingress Controller..."
          kustomize build --enable-helm infrastructure/platforms/networking/nginx-ingress/ | kubectl delete -f - --ignore-not-found=true || true
          kubectl delete namespace ingress-nginx --ignore-not-found=true || true

          # Clean up Cert-Manager
          echo "ğŸ—‘ï¸ Cleaning up Cert-Manager..."
          kustomize build --enable-helm infrastructure/platforms/networking/cert-manager/ | kubectl delete -f - --ignore-not-found=true || true
          kubectl delete namespace cert-manager --ignore-not-found=true || true

          # Clean up Grafana
          echo "ğŸ—‘ï¸ Cleaning up Grafana..."
          kustomize build --enable-helm infrastructure/platforms/monitoring/grafana/ | kubectl delete -f - --ignore-not-found=true || true

          # Clean up Prometheus
          echo "ğŸ—‘ï¸ Cleaning up Prometheus..."
          kustomize build --enable-helm infrastructure/platforms/monitoring/prometheus/ | kubectl delete -f - --ignore-not-found=true || true

          # Clean up External DNS (if it exists)
          echo "ğŸ—‘ï¸ Cleaning up External DNS..."
          kubectl delete -k infrastructure/platforms/networking/external-dns/ --ignore-not-found=true || true
          kubectl delete namespace external-dns --ignore-not-found=true || true

          # Wait for cleanup to complete
          echo "â³ Waiting for cleanup to complete..."
          sleep 20

          # Verify cleanup
          echo "ğŸ” Verifying cleanup..."
          for namespace in ingress-nginx cert-manager external-dns; do
            if kubectl get namespace $namespace >/dev/null 2>&1; then
              echo "âš ï¸ Namespace $namespace still exists, waiting longer..."
              sleep 5
            fi
          done

          echo "âœ… Platform components cleanup completed"

      - name: Deploy NGINX Ingress Controller
        run: |
          echo "ğŸŒ Deploying NGINX Ingress Controller..."
          if [ "${{ github.event.inputs.dry_run || 'false' }}" = "true" ]; then
            echo "ğŸ” DRY RUN MODE - Showing what would be deployed..."
            kustomize build --enable-helm infrastructure/platforms/networking/nginx-ingress/ | kubectl apply --dry-run=client -f -
          else
            echo "ğŸš€ Deploying NGINX Ingress Controller..."
            kustomize build --enable-helm infrastructure/platforms/networking/nginx-ingress/ | kubectl apply -f -
          fi

      - name: Wait for NGINX Ingress Controller
        if: github.event.inputs.dry_run != 'true'
        run: |
          echo "â³ Waiting for NGINX Ingress Controller to be ready..."

          # Wait for deployment to be available
          kubectl wait --namespace ingress-nginx \
            --for=condition=available deployment/ingress-nginx-controller \
            --timeout=600s

          echo "ğŸ“Š Deployment is available, checking pod status..."
          kubectl get pods -n ingress-nginx

          # Verify at least one controller pod is running
          echo "â³ Verifying controller pods are running..."
          RUNNING_PODS=$(kubectl get pods -n ingress-nginx -l app.kubernetes.io/name=ingress-nginx,app.kubernetes.io/component=controller --field-selector=status.phase=Running --no-headers | wc -l)
          if [ "$RUNNING_PODS" -gt 0 ]; then
            echo "âœ… Found $RUNNING_PODS running controller pod(s)"
          else
            echo "âš ï¸ No running controller pods found, checking pod details..."
            kubectl get pods -n ingress-nginx -o wide
            kubectl describe pods -n ingress-nginx
            kubectl get events -n ingress-nginx --sort-by='.lastTimestamp'
            echo "âš ï¸ Continuing anyway as deployment is available..."
          fi

          echo "âœ… NGINX Ingress Controller deployment is available"

          # Check service and get external IP
          echo "ğŸŒ Checking NGINX Ingress service..."
          kubectl get svc -n ingress-nginx

          # Wait for external IP to be assigned (with timeout)
          echo "â³ Waiting for external IP assignment..."
          timeout 300 bash -c 'until kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath="{.status.loadBalancer.ingress[0].ip}" | grep -q "."; do echo "Waiting for external IP..."; sleep 10; done' || {
            echo "âš ï¸ External IP not assigned within timeout, continuing..."
          }

          # Show final status
          echo "ğŸ“Š Final NGINX Ingress status:"
          kubectl get svc -n ingress-nginx ingress-nginx-controller

      - name: Deploy Cert-Manager
        run: |
          echo "ğŸ” Deploying Cert-Manager..."
          if [ "${{ github.event.inputs.dry_run || 'false' }}" = "true" ]; then
            kustomize build --enable-helm infrastructure/platforms/networking/cert-manager/ | kubectl apply --dry-run=client -f -
          else
            kustomize build --enable-helm infrastructure/platforms/networking/cert-manager/ | kubectl apply -f -
          fi

      - name: Wait for Cert-Manager
        if: github.event.inputs.dry_run != 'true'
        run: |
          echo "â³ Waiting for Cert-Manager to be ready..."
          kubectl wait --namespace cert-manager \
            --for=condition=ready pod \
            --selector=app.kubernetes.io/component=controller \
            --timeout=300s || {
            echo "âš ï¸ Cert-Manager ready check failed, checking pod status..."
            kubectl get pods -n cert-manager -o wide
            kubectl describe pods -n cert-manager
            echo "âš ï¸ Continuing anyway..."
          }


      - name: Deploy External DNS
        run: |
          echo "ğŸŒ Deploying External DNS..."
          if [ "${{ github.event.inputs.dry_run || 'false' }}" = "true" ]; then
            kustomize build infrastructure/platforms/networking/external-dns/ | kubectl apply --dry-run=client -f -
          else
            # Deploy External DNS and ignore ServiceMonitor errors (expected when Prometheus not installed)
            kustomize build infrastructure/platforms/networking/external-dns/ | kubectl apply -f - || {
              echo "âš ï¸ External DNS deployment completed with expected ServiceMonitor error (Prometheus not installed)"
              echo "âœ… Core External DNS components deployed successfully"
            }
          fi

      - name: Create AWS Credentials Secret
        if: github.event.inputs.dry_run != 'true'
        run: |
          echo "ğŸ” Creating AWS credentials secret for External DNS..."
          
          # Wait for external-dns namespace to be created
          echo "â³ Waiting for external-dns namespace to be created..."
          kubectl wait --for=condition=Active namespace/external-dns --timeout=60s || {
            echo "âš ï¸ Namespace creation timeout, checking if it exists..."
            kubectl get namespace external-dns || {
              echo "âŒ external-dns namespace not found, creating it manually..."
              kubectl create namespace external-dns
            }
          }
          
          # Check if secret already exists
          if kubectl get secret aws-credentials -n external-dns >/dev/null 2>&1; then
            echo "âœ… AWS credentials secret already exists, updating..."
            kubectl delete secret aws-credentials -n external-dns
          fi
          
          # Create the secret with AWS credentials from GitHub secrets
          kubectl create secret generic aws-credentials \
            --namespace=external-dns \
            --from-literal=aws-access-key-id="${{ secrets.AWS_ACCESS_KEY_ID }}" \
            --from-literal=aws-secret-access-key="${{ secrets.AWS_SECRET_ACCESS_KEY }}"
          
          echo "âœ… AWS credentials secret created for External DNS"
          
          # Restart External DNS deployment to pick up the new credentials (if it exists)
          echo "ğŸ”„ Restarting External DNS deployment to use new credentials..."
          if kubectl get deployment external-dns -n external-dns >/dev/null 2>&1; then
            kubectl rollout restart deployment/external-dns -n external-dns
            echo "âœ… External DNS deployment restarted"
          else
            echo "âš ï¸ External DNS deployment not found, it will pick up credentials on first start"
          fi

      - name: Wait for External DNS
        if: github.event.inputs.dry_run != 'true'
        run: |
          echo "â³ Waiting for External DNS to be ready..."
          kubectl wait --namespace external-dns \
            --for=condition=ready pod \
            --selector=app.kubernetes.io/name=external-dns \
            --timeout=300s || {
            echo "âš ï¸ External DNS ready check failed, checking pod status..."
            kubectl get pods -n external-dns -o wide
            kubectl describe pods -n external-dns
            echo "âš ï¸ Continuing anyway..."
          }

      - name: Deploy Prometheus
        run: |
          echo "ğŸ“Š Deploying Prometheus..."
          if [ "${{ github.event.inputs.dry_run || 'false' }}" = "true" ]; then
            kustomize build --enable-helm infrastructure/platforms/monitoring/prometheus/ | kubectl apply --dry-run=client -f -
          else
            kustomize build --enable-helm infrastructure/platforms/monitoring/prometheus/ | kubectl apply -f -
          fi

      - name: Wait for Prometheus
        if: github.event.inputs.dry_run != 'true'
        run: |
          echo "â³ Waiting for Prometheus to be ready..."
          kubectl wait --namespace monitoring \
            --for=condition=ready pod \
            --selector=app.kubernetes.io/name=prometheus \
            --timeout=300s || {
            echo "âš ï¸ Prometheus ready check failed, checking pod status..."
            kubectl get pods -n monitoring -o wide
            kubectl describe pods -n monitoring
            echo "âš ï¸ Continuing anyway..."
          }

      - name: Create Grafana Admin Secret
        if: github.event.inputs.dry_run != 'true'
        run: |
          echo "ğŸ” Creating Grafana admin secret..."
          
          # Ensure monitoring namespace exists
          kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -
          
          # Check if secret already exists
          if kubectl get secret grafana-admin-secret -n monitoring >/dev/null 2>&1; then
            echo "âœ… Grafana admin secret already exists"
          else
            # Create the secret with default admin credentials
            echo "ğŸ“ Creating new Grafana admin secret..."
            kubectl create secret generic grafana-admin-secret \
              --namespace=monitoring \
              --from-literal=admin-user=admin \
              --from-literal=admin-password="$(openssl rand -base64 32)"
            echo "âœ… Grafana admin secret created successfully"
          fi

      - name: Deploy Grafana
        run: |
          echo "ğŸ“ˆ Deploying Grafana..."
          if [ "${{ github.event.inputs.dry_run || 'false' }}" = "true" ]; then
            kustomize build --enable-helm infrastructure/platforms/monitoring/grafana/ | kubectl apply --dry-run=client -f -
          else
            # Check if Grafana is already running
            if kubectl get pods -n monitoring -l app.kubernetes.io/name=grafana --no-headers | grep -q Running; then
              echo "âœ… Grafana is already running, skipping deployment"
            else
              # Deploy Grafana and ignore ServiceMonitor errors (expected when Prometheus not installed)
              kustomize build --enable-helm infrastructure/platforms/monitoring/grafana/ | kubectl apply -f - || {
                echo "âš ï¸ Grafana deployment completed with expected ServiceMonitor error (Prometheus not installed)"
                echo "âœ… Core Grafana components deployed successfully"
              }
            fi
          fi

      - name: Wait for Grafana
        if: github.event.inputs.dry_run != 'true'
        run: |
          echo "â³ Waiting for Grafana to be ready..."
          # Wait for the Grafana deployment to be available (longer timeout for PVC creation)
          kubectl wait --namespace monitoring \
            --for=condition=available deployment/grafana \
            --timeout=600s || {
            echo "âš ï¸ Grafana deployment timeout, checking status..."
            kubectl get pods -n monitoring -l app.kubernetes.io/name=grafana -o wide
            kubectl describe pods -n monitoring -l app.kubernetes.io/name=grafana
            kubectl describe deployment -n monitoring grafana
            kubectl get pvc -n monitoring
            echo "âš ï¸ Continuing anyway..."
          }

          # Verify the main Grafana pod is running (if deployment succeeded)
          if kubectl get deployment grafana -n monitoring >/dev/null 2>&1; then
            kubectl get pods -n monitoring -l app.kubernetes.io/name=grafana,app.kubernetes.io/instance=grafana
            echo "âœ… Grafana deployment is ready"
          else
            echo "âš ï¸ Grafana deployment not found"
          fi

  deploy-applications:
    needs:
      [detect-environment, check-component-versions, deploy-platform-components]
    if: needs.detect-environment.outputs.should_deploy == 'true' && (needs.check-component-versions.outputs.deploy_applications == 'true' || github.event.inputs.force_deploy == 'true')
    runs-on: ubuntu-latest
    environment: ${{ needs.detect-environment.outputs.environment }}
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Login to Azure
        uses: azure/login@v2
        with:
          client-id: ${{ env.AZURE_CLIENT_ID }}
          tenant-id: ${{ env.AZURE_TENANT_ID }}
          subscription-id: ${{ env.AZURE_SUBSCRIPTION_ID }}

      - name: Get AKS credentials
        run: |
          az aks get-credentials \
            --resource-group ${{ needs.detect-environment.outputs.resource_group }} \
            --name ${{ needs.detect-environment.outputs.cluster_name }} \
            --overwrite-existing

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ env.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Update Application Versions Dynamically
        run: |
          echo "ğŸ”„ Updating application versions from global configuration..."
          ./scripts/update-component-versions.sh

      - name: Clean up existing applications
        if: github.event.inputs.dry_run != 'true'
        run: |
          echo "ğŸ§¹ Cleaning up existing applications to avoid immutable field conflicts..."

          # Clean up ArgoCD using Helm (since it's deployed with Helm)
          echo "ğŸ—‘ï¸ Cleaning up ArgoCD (Helm uninstall)..."
          helm uninstall argocd -n argocd --ignore-not-found || true

          # Clean up any remaining resources
          kubectl delete namespace argocd --ignore-not-found=true || true

          # Clean up Backstage using Kustomize (since it's deployed with Kustomize)
          echo "ğŸ—‘ï¸ Cleaning up Backstage (Kustomize delete)..."
          kubectl delete -k infrastructure/applications/backstage/ --ignore-not-found=true || true

          # Clean up Crossplane using Kustomize (since it's deployed with Kustomize + Helm charts)
          echo "ğŸ—‘ï¸ Cleaning up Crossplane (Kustomize delete)..."
          kubectl delete -k infrastructure/applications/crossplane/ --ignore-not-found=true || true

          echo "â³ Waiting for cleanup to complete..."
          sleep 15
          echo "âœ… Cleanup completed"

      - name: Setup Helm Repositories
        run: |
          echo "ğŸ“¦ Setting up Helm repositories..."
          helm repo add argo https://argoproj.github.io/argo-helm
          helm repo update
          echo "âœ… Helm repositories configured"

      - name: Generate Dynamic Configurations
        run: |
          echo "ğŸ”§ Generating dynamic configurations for all Helm components from global.yaml..."

          # Make the script executable
          chmod +x scripts/utilities/generate-all-helm-configs.sh

          # Generate all Helm component configurations
          echo "ğŸ“ Generating all Helm component configurations..."
          ./scripts/utilities/generate-all-helm-configs.sh

          # Show what was generated
          echo "ğŸ“‹ Generated configurations:"
          echo "  ğŸ“¦ Platform Components:"
          echo "    - NGINX Ingress: $(wc -l < infrastructure/platforms/networking/nginx-ingress/helm-values.yaml) lines"
          echo "    - Cert-Manager: $(wc -l < infrastructure/platforms/networking/cert-manager/helm-values.yaml) lines"
          echo "    - Grafana: $(wc -l < infrastructure/platforms/monitoring/grafana/helm-values.yaml) lines"
          echo "    - Prometheus: $(wc -l < infrastructure/platforms/monitoring/prometheus/helm-values.yaml) lines"
          echo "  ğŸ“¦ Applications:"
          echo "    - ArgoCD: $(wc -l < infrastructure/applications/argocd/helm-values.yaml) lines"
          echo "    - Crossplane: $(wc -l < infrastructure/applications/crossplane/helm-values.yaml) lines"

          # Verify the generated configurations
          echo "ğŸ” Verifying generated configurations..."
          local failed=0
          for component in "nginx-ingress" "cert-manager" "grafana" "prometheus" "argocd" "crossplane"; do
            if [ -f "infrastructure/platforms/networking/${component}/helm-values.yaml" ] || [ -f "infrastructure/platforms/monitoring/${component}/helm-values.yaml" ] || [ -f "infrastructure/applications/${component}/helm-values.yaml" ]; then
              echo "  âœ… $component configuration generated"
            else
              echo "  âŒ $component configuration missing"
              failed=1
            fi
          done

          if [ $failed -eq 1 ]; then
            echo "âŒ Configuration generation failed"
            exit 1
          else
            echo "âœ… All configuration files generated successfully"
          fi

      - name: Commit Generated Configurations
        if: github.event.inputs.dry_run != 'true'
        run: |
          echo "ğŸ’¾ Committing generated configuration files..."

          # Configure git
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"

          # Check if there are changes to commit
          if git diff --quiet; then
            echo "â„¹ï¸ No changes to commit"
          else
            # Add and commit the generated files
            git add infrastructure/platforms/networking/nginx-ingress/helm-values.yaml
            git add infrastructure/platforms/networking/nginx-ingress/kustomization.yaml
            git add infrastructure/platforms/networking/cert-manager/helm-values.yaml
            git add infrastructure/platforms/networking/cert-manager/kustomization.yaml
            git add infrastructure/platforms/monitoring/grafana/helm-values.yaml
            git add infrastructure/platforms/monitoring/grafana/kustomization.yaml
            git add infrastructure/platforms/monitoring/prometheus/helm-values.yaml
            git add infrastructure/platforms/monitoring/prometheus/kustomization.yaml
            git add infrastructure/applications/argocd/helm-values.yaml
            git add infrastructure/applications/argocd/kustomization.yaml
            git add infrastructure/applications/crossplane/helm-values.yaml
            git add infrastructure/applications/crossplane/kustomization.yaml
            git commit -m "ğŸ¤– Auto-update: Generate all Helm component configurations from global.yaml" -m "- Generated configurations for: NGINX Ingress, Cert-Manager, Grafana, Prometheus, ArgoCD, Crossplane" -m "- Generated helm-values.yaml and kustomization.yaml from global.yaml" -m "- Ensures consistency across all configuration files" -m "- Auto-generated by pipeline - do not edit manually" -m "Generated from: ${{ github.sha }}"
            
            # Push the changes
            git push origin ${{ github.ref_name }}
            echo "âœ… Generated configurations committed and pushed"
          fi

      - name: Deploy Applications
        run: |
          echo "ğŸš€ Deploying Applications..."

          # Extract chart version from generated kustomization.yaml
          ARGOCD_CHART_VERSION=$(yq eval '.helmCharts[0].version' infrastructure/applications/argocd/kustomization.yaml)
          echo "ğŸ“‹ Using ArgoCD chart version: $ARGOCD_CHART_VERSION"

          if [ "${{ github.event.inputs.dry_run || 'false' }}" = "true" ]; then
            echo "ğŸ” DRY RUN MODE - Showing what would be deployed..."
            
            # Deploy ArgoCD with Helm (dry run)
            echo "ğŸ“¦ ArgoCD (Helm dry run):"
            helm install argocd argo/argo-cd -n argocd -f infrastructure/applications/argocd/helm-values.yaml --version "$ARGOCD_CHART_VERSION" --dry-run --debug || true
            
            # Deploy other applications with Kustomize (dry run)
            echo "ğŸ“¦ Other Applications (Kustomize dry run):"
            kustomize build --enable-helm infrastructure/applications/backstage/ | kubectl apply --dry-run=client -f - || true
            kustomize build --enable-helm infrastructure/applications/crossplane/ | kubectl apply --dry-run=client -f - || true
          else
            # Deploy ArgoCD with Helm
            echo "ğŸ“¦ Deploying ArgoCD with Helm..."
            helm install argocd argo/argo-cd -n argocd -f infrastructure/applications/argocd/helm-values.yaml --version "$ARGOCD_CHART_VERSION"
            
            # Deploy other applications with Kustomize
            echo "ğŸ“¦ Deploying other applications with Kustomize..."
            kustomize build --enable-helm infrastructure/applications/backstage/ | kubectl apply -f -
            kustomize build --enable-helm infrastructure/applications/crossplane/ | kubectl apply -f -
          fi

      - name: Verify Application Deployments
        if: github.event.inputs.dry_run != 'true'
        run: |
          echo "ğŸ” Verifying application deployments..."

          # Wait for ArgoCD to be ready
          echo "â³ Waiting for ArgoCD to be ready..."
          kubectl wait --namespace argocd \
            --for=condition=available deployment/argocd-server \
            --timeout=300s || { echo "âŒ ArgoCD server failed to start"; kubectl get pods -n argocd; exit 1; }

          # Wait for Backstage to be ready
          echo "â³ Waiting for Backstage to be ready..."
          kubectl wait --namespace backstage \
            --for=condition=available deployment/backstage \
            --timeout=300s || { echo "âŒ Backstage failed to start"; kubectl get pods -n backstage; exit 1; }

          # Wait for Crossplane to be ready
          echo "â³ Waiting for Crossplane to be ready..."
          kubectl wait --namespace crossplane-system \
            --for=condition=available deployment/crossplane \
            --timeout=300s || { echo "âŒ Crossplane failed to start"; kubectl get pods -n crossplane-system; exit 1; }

          echo "âœ… All applications deployed successfully"

  verify-deployment:
    needs:
      [
        detect-environment,
        check-component-versions,
        deploy-platform-components,
        deploy-applications,
      ]
    if: always() && needs.detect-environment.outputs.should_deploy == 'true'
    runs-on: ubuntu-latest
    environment: ${{ needs.detect-environment.outputs.environment }}
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Login to Azure
        uses: azure/login@v2
        with:
          client-id: ${{ env.AZURE_CLIENT_ID }}
          tenant-id: ${{ env.AZURE_TENANT_ID }}
          subscription-id: ${{ env.AZURE_SUBSCRIPTION_ID }}

      - name: Get AKS credentials
        run: |
          az aks get-credentials \
            --resource-group ${{ needs.detect-environment.outputs.resource_group }} \
            --name ${{ needs.detect-environment.outputs.cluster_name }} \
            --overwrite-existing

      - name: Verify Deployment
        run: |
          echo "ğŸ” Verifying deployment..."

          # Check all components
          echo "ğŸ“Š Component Status:"
          kubectl get pods -n ingress-nginx
          kubectl get pods -n cert-manager
          kubectl get pods -n external-dns
          kubectl get pods -n monitoring
          kubectl get pods -n argocd
          kubectl get pods -n backstage
          kubectl get pods -n crossplane-system

          # Check ArgoCD applications
          echo "ğŸ”„ ArgoCD Applications:"
          kubectl get applications -n argocd

          # Test application access
          echo "ğŸŒ Testing application access..."
          INGRESS_IP=$(kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
          echo "Ingress IP: $INGRESS_IP"

          # Test ArgoCD access
          if curl -I -s --max-time 10 "https://argocd.${{ needs.detect-environment.outputs.environment }}.aztech-msdp.com" | grep -q "200\|302"; then
            echo "âœ… ArgoCD is accessible"
          else
            echo "âŒ ArgoCD access failed"
          fi

          # Test Grafana access
          if curl -I -s --max-time 10 "https://grafana.${{ needs.detect-environment.outputs.environment }}.aztech-msdp.com" | grep -q "200\|302"; then
            echo "âœ… Grafana is accessible"
          else
            echo "âŒ Grafana access failed"
          fi

          echo "âœ… Deployment verification completed"
