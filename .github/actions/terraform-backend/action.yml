name: "Terraform Backend (AWS)"
description: "Creates/ensures Terraform S3 state bucket and DynamoDB lock table, and writes backend-config.json."

inputs:
  repo-shortname:
    description: "Shortname of the repository (e.g., infra)"
    required: true
  project:
    description: "Project name (e.g., msdp)"
    required: true
  env:
    description: "Environment (e.g., dev, sit, prod)"
    required: true
  app:
    description: "Application/workload name (e.g., crossplane)"
    required: true
  function:
    description: "Function for bucket grouping (e.g., tfstate)"
    required: true
  pipeline-name:
    description: "Logical name for the pipeline or workflow using this backend (e.g., provisioner, addons, bootstrap). If empty, computed from repo/env/cloud/app/key-salt"
    required: false
  key-salt:
    description: "Recommended: TF working directory path for stable pipeline name generation"
    required: false
  allow-key-mutation:
    description: "Allow changing backend key if it would differ from existing config (default: false)"
    required: false
    default: "false"
  cloud-segment:
    description: "Cloud segment for key path (e.g., aws, azure)"
    required: true
  cloud:
    description: "Target cloud; only 'aws' is supported for now"
    required: true
  aws-account-id:
    description: "AWS account ID for backend uniqueness"
    required: true
  aws-region:
    description: "AWS region for the backend"
    required: false
    default: "eu-west-1"
  use-shared-lock-table:
    description: "Use a shared DynamoDB lock table for all pipelines (default: true)"
    required: false
    default: "true"
  lock-table-name:
    description: "Custom lock table name (if not provided, derived from account/region)"
    required: false

runs:
  using: "composite"
  steps:
    - name: Validate inputs
      shell: bash
      run: |
        set -euo pipefail
        if [[ "${{ inputs.cloud }}" != "aws" ]]; then
          echo "ERROR: Only cloud=aws is supported at this time." >&2
          exit 1
        fi
        if [[ -z "${{ inputs.function }}" ]]; then
          echo "ERROR: function input is required and cannot be empty." >&2
          exit 1
        fi
        if [[ -z "${{ inputs.aws-account-id }}" ]]; then
          echo "ERROR: aws-account-id input is required and cannot be empty." >&2
          exit 1
        fi

    - name: Prepare paths and env
      shell: bash
      run: |
        set -euo pipefail
        BACKEND_DIR="infrastructure/environment/${{ inputs.env }}/backend"
        mkdir -p "$BACKEND_DIR"
        CFG="$BACKEND_DIR/backend-config.json"
        echo "BACKEND_DIR=$BACKEND_DIR" >> "$GITHUB_ENV"
        echo "CFG=$CFG" >> "$GITHUB_ENV"

    - name: Determine or generate bucket name
      shell: bash
      run: |
        set -euo pipefail
        : "${CFG:?CFG not set}"
        BUCKET=""
        if [[ -f "$CFG" ]]; then
          BUCKET="$(jq -r '.bucket // empty' "$CFG" 2>/dev/null || echo "")"
        fi
        if [[ -z "$BUCKET" ]]; then
          # Stable bucket naming: <repo>-<project>-<env>-<function>-<account-id>-<region>
          REGION_SHORT="$(echo "${{ inputs.aws-region }}" | sed 's/eu-west-/euw/;s/us-east-/use/;s/us-west-/usw/')"
          BUCKET="${{ inputs.repo-shortname }}-${{ inputs.project }}-${{ inputs.env }}-${{ inputs.function }}-${{ inputs.aws-account-id }}-${REGION_SHORT}"
          # Normalize to lowercase and safe chars
          BUCKET="$(echo "$BUCKET" | tr '[:upper:]' '[:lower:]' | sed -E 's/[^a-z0-9-]+/-/g')"
          
          # Basic length/syntax guard
          if [[ ${#BUCKET} -gt 63 ]]; then
            echo "ERROR: Bucket name too long: $BUCKET" >&2
            exit 1
          fi
        fi
        echo "BUCKET=$BUCKET" >> "$GITHUB_ENV"

    - name: Determine pipeline name and build key
      shell: bash
      run: |
        set -euo pipefail
        : "${CFG:?CFG not set}"
        : "${BUCKET:?BUCKET not set}"

        # DynamoDB table name selection
        if [[ "${{ inputs.use-shared-lock-table }}" == "true" ]]; then
          if [[ -n "${{ inputs.lock-table-name }}" && "${{ inputs.lock-table-name }}" != "null" ]]; then
            # Use provided custom table name
            TABLE="${{ inputs.lock-table-name }}"
            echo "Using custom shared lock table: $TABLE"
          else
            # Derive shared table name from account/region
            aws_region="${{ inputs.aws-region }}"
            case "$aws_region" in
              eu-west-1) aws_region_short="euw1" ;;
              eu-west-2) aws_region_short="euw2" ;;
              eu-west-3) aws_region_short="euw3" ;;
              eu-central-1) aws_region_short="euc1" ;;
              us-east-1) aws_region_short="use1" ;;
              us-east-2) aws_region_short="use2" ;;
              us-west-1) aws_region_short="usw1" ;;
              us-west-2) aws_region_short="usw2" ;;
              *) aws_region_short="$aws_region" ;;
            esac
            TABLE="tfstate-locks-${{ inputs.aws-account-id }}-${aws_region_short}"
            echo "Using derived shared lock table: $TABLE"
          fi
        else
          # Legacy behavior: per-bucket table
          TABLE="${BUCKET}-locks"
          echo "Using legacy per-bucket lock table: $TABLE"
        fi

        # Check if backend-config.json exists and read existing pipeline_name
        EXISTING_PIPELINE_NAME=""
        if [[ -f "$CFG" ]]; then
          EXISTING_PIPELINE_NAME=$(jq -r '.pipeline_name // empty' "$CFG" 2>/dev/null || echo "")
        fi

        # Determine pipeline_name
        PIPELINE_NAME_INPUT="${{ inputs.pipeline-name }}"
        if [[ -n "$EXISTING_PIPELINE_NAME" ]]; then
          # Reuse existing pipeline_name
          pipeline_name="$EXISTING_PIPELINE_NAME"
          echo "Reusing existing pipeline_name: $pipeline_name"
        elif [[ -n "${PIPELINE_NAME_INPUT}" && "${PIPELINE_NAME_INPUT}" != "null" ]]; then
          # Use provided pipeline_name
          pipeline_name="$PIPELINE_NAME_INPUT"
          echo "Using provided pipeline_name: $pipeline_name"
        else
          # Compute stable fallback with shorter format
          cloud_segment="${{ inputs.cloud-segment }}"
          if [[ -z "$cloud_segment" || "$cloud_segment" == "null" ]]; then cloud_segment="${{ inputs.cloud }}"; fi
          KEY_SALT="${{ inputs.key-salt }}"
          BASE="${GITHUB_REPOSITORY}|${{ inputs.env }}|${cloud_segment}|${{ inputs.app }}|${KEY_SALT}"
          
          # Extract repo name from GITHUB_REPOSITORY (org/repo -> repo)
          slug_repo="$(echo "$GITHUB_REPOSITORY" | cut -d'/' -f2 | tr '[:upper:]' '[:lower:]')"
          hash8="$(echo -n "$BASE" | sha1sum | cut -c1-8)"
          
          # Build pipeline_name with shorter format
          pipeline_name="tf-${slug_repo}-${{ inputs.env }}-${cloud_segment}-${{ inputs.app }}-${hash8}"
          
          # Normalize and truncate if needed
          pipeline_name="$(echo "$pipeline_name" | sed -E 's/[^a-z0-9-]+/-/g; s/-+/-/g; s/^-|-$//g')"
          if [[ ${#pipeline_name} -gt 63 ]]; then
            pipeline_name="${pipeline_name:0:63}"
          fi
          
          echo "Computed stable pipeline_name: $pipeline_name"
        fi

        # Build KEY using pipeline_name
        cloud_segment="${{ inputs.cloud-segment }}"
        if [[ -z "$cloud_segment" || "$cloud_segment" == "null" ]]; then cloud_segment="${{ inputs.cloud }}"; fi
        KEY="${{ inputs.repo-shortname }}/${{ inputs.project }}/${{ inputs.env }}/${cloud_segment}/${{ inputs.app }}/$pipeline_name.tfstate"

        # Safety check: prevent accidental state moves
        if [[ -f "$CFG" ]]; then
          EXISTING_KEY=$(jq -r '.key // empty' "$CFG" 2>/dev/null || echo "")
          if [[ -n "$EXISTING_KEY" && "$EXISTING_KEY" != "$KEY" ]]; then
            if [[ "${{ inputs.allow-key-mutation }}" != "true" ]]; then
              echo "ERROR: Refusing to change backend key from '$EXISTING_KEY' to '$KEY'. Set allow-key-mutation=true to override." >&2
              exit 1
            else
              echo "WARNING: Changing backend key from '$EXISTING_KEY' to '$KEY' (allow-key-mutation=true)"
            fi
          fi
        fi

        echo "TABLE=$TABLE" >> "$GITHUB_ENV"
        echo "KEY=$KEY" >> "$GITHUB_ENV"
        echo "PIPELINE_NAME=$pipeline_name" >> "$GITHUB_ENV"

    - name: Ensure S3 bucket exists
      shell: bash
      run: |
        set -euo pipefail
        : "${BUCKET:?BUCKET not set}"
        set +e
        aws s3api head-bucket --bucket "$BUCKET" >/dev/null 2>&1
        EXISTS=$?
        set -e
        if [[ $EXISTS -ne 0 ]]; then
          aws s3api create-bucket --bucket "$BUCKET" --region "${{ inputs.aws-region }}" \
            --create-bucket-configuration LocationConstraint="${{ inputs.aws-region }}"
        fi

    - name: Configure bucket (versioning, encryption, tags)
      shell: bash
      run: |
        set -euo pipefail
        : "${BUCKET:?BUCKET not set}"
        aws s3api put-bucket-versioning --bucket "$BUCKET" --versioning-configuration Status=Enabled
        aws s3api put-bucket-encryption --bucket "$BUCKET" --server-side-encryption-configuration '{
          "Rules":[{"ApplyServerSideEncryptionByDefault":{"SSEAlgorithm":"AES256"}}]
        }'
        # Tag bucket using jq to generate JSON file
        jq -n \
          --arg repo "${{ inputs.repo-shortname }}" \
          --arg project "${{ inputs.project }}" \
          --arg env "${{ inputs.env }}" \
          --arg app "${{ inputs.app }}" \
          --arg function "${{ inputs.function }}" \
          '{TagSet: [
            {Key: "Repo", Value: $repo},
            {Key: "Project", Value: $project},
            {Key: "Environment", Value: $env},
            {Key: "App", Value: $app},
            {Key: "Function", Value: $function}
          ]}' > tags.json
        echo "Applied tags: $(cat tags.json)"
        aws s3api put-bucket-tagging --bucket "$BUCKET" --tagging file://tags.json
        rm -f tags.json

    - name: Ensure DynamoDB lock table
      shell: bash
      run: |
        set -euo pipefail
        : "${TABLE:?TABLE not set}"
        set +e
        aws dynamodb describe-table --table-name "$TABLE" >/dev/null 2>&1
        EXISTS=$?
        set -e
        if [[ $EXISTS -ne 0 ]]; then
          aws dynamodb create-table \
            --table-name "$TABLE" \
            --attribute-definitions AttributeName=LockID,AttributeType=S \
            --key-schema AttributeName=LockID,KeyType=HASH \
            --billing-mode PAY_PER_REQUEST
          
          # Enable Point-in-Time Recovery if permissions allow (ignore failure)
          echo "Attempting to enable Point-in-Time Recovery for table: $TABLE"
          set +e
          aws dynamodb update-continuous-backups \
            --table-name "$TABLE" \
            --point-in-time-recovery-specification PointInTimeRecoveryEnabled=true
          if [[ $? -eq 0 ]]; then
            echo "✓ Point-in-Time Recovery enabled for $TABLE"
          else
            echo "⚠ Could not enable Point-in-Time Recovery for $TABLE (insufficient permissions or not supported)"
          fi
          set -e
        fi

    - name: Write backend-config.json
      shell: bash
      run: |
        set -euo pipefail
        : "${CFG:?CFG not set}"
        : "${BUCKET:?BUCKET not set}"
        : "${KEY:?KEY not set}"
        : "${TABLE:?TABLE not set}"
        : "${PIPELINE_NAME:?PIPELINE_NAME not set}"
        jq -n --arg bucket "$BUCKET" \
              --arg key "$KEY" \
              --arg region "${{ inputs.aws-region }}" \
              --arg table "$TABLE" \
              --arg pipeline_name "$PIPELINE_NAME" \
              '{bucket:$bucket, key:$key, region:$region, dynamodb_table:$table, pipeline_name:$pipeline_name}' > "$CFG"
        echo "Wrote $CFG"
        cat "$CFG"

    - name: Verify backend-config present
      shell: bash
      run: |
        set -euo pipefail
        : "${CFG:?CFG not set}"
        echo "Checking backend config at $CFG"
        test -f "$CFG"
        jq -C . "$CFG" || cat "$CFG"

    - name: Summary
      shell: bash
      run: |
        set -euo pipefail
        : "${BUCKET:?BUCKET not set}"
        : "${TABLE:?TABLE not set}"
        : "${KEY:?KEY not set}"
        : "${PIPELINE_NAME:?PIPELINE_NAME not set}"
        echo "Backend summary:"
        echo "BUCKET=$BUCKET"
        if [[ "${{ inputs.use-shared-lock-table }}" == "true" ]]; then
          echo "TABLE=$TABLE (SHARED)"
        else
          echo "TABLE=$TABLE (PER-BUCKET)"
        fi
        echo "KEY=$KEY"
        echo "PIPELINE_NAME=$PIPELINE_NAME"
        aws s3api get-bucket-versioning --bucket "$BUCKET" --query 'Status'
        aws s3api get-bucket-encryption --bucket "$BUCKET" \
          --query 'ServerSideEncryptionConfiguration.Rules[*].ApplyServerSideEncryptionByDefault.SSEAlgorithm'
        aws dynamodb describe-table --table-name "$TABLE" --query '{Status:Table.TableStatus,Key:Table.KeySchema}'
