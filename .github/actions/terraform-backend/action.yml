name: Terraform Backend (AWS)
description: Creates/ensures Terraform S3 state bucket and DynamoDB lock table,
  and writes backend-config.json.

inputs:
  repo-shortname:
    description: Shortname of the repository (e.g., infra)
    required: true
  project:
    description: Project name (e.g., msdp)
    required: true
  env:
    description: Environment (e.g., dev, sit, prod)
    required: true
  app:
    description: Application/workload name (e.g., crossplane)
    required: true
  function:
    description: Function for bucket grouping (e.g., tfstate)
    required: true
  pipeline-name:
    description: Logical name for the pipeline or workflow using this backend (e.g.,
      provisioner, addons, bootstrap). If empty, computed from
      repo/env/cloud/app/key-salt
    required: false
  key-salt:
    description: 'Recommended: TF working directory path for stable pipeline name
      generation'
    required: false
  allow-key-mutation:
    description: 'Allow changing backend key if it would differ from existing config
      (default: false)'
    required: false
    default: 'false'
  cloud-segment:
    description: Cloud segment for key path (e.g., aws, azure)
    required: true
  cloud:
    description: Target cloud; only 'aws' is supported for now
    required: true
  aws-account-id:
    description: AWS account ID for backend uniqueness. If not provided, will be
      auto-resolved from config files
    required: false
  aws-region:
    description: AWS region for the backend
    required: false
    default: eu-west-1
  use-shared-lock-table:
    description: 'Use a shared DynamoDB lock table for all pipelines (default: true)'
    required: false
    default: 'true'
  lock-table-name:
    description: Custom lock table name (if not provided, derived from account/region)
    required: false

outputs:
  config-file:
    description: Path to the generated backend-config.json file
    value: ${{ steps.prepare-paths.outputs.cfg }}
  bucket:
    description: S3 bucket name for terraform state
    value: ${{ steps.determine-bucket.outputs.bucket }}
  dynamodb-table:
    description: DynamoDB table name for terraform locks
    value: ${{ steps.determine-pipeline.outputs.table }}
  key:
    description: Terraform state file key
    value: ${{ steps.determine-pipeline.outputs.key }}

runs:
  using: composite
  steps:
    - name: Validate inputs
      shell: bash
      run: |
        set -euo pipefail
        if [[ "${{ inputs.cloud }}" != "aws" ]]; then
          echo "ERROR: Only cloud=aws is supported at this time." >&2
          exit 1
        fi
        if [[ -z "${{ inputs.function }}" ]]; then
          echo "ERROR: function input is required and cannot be empty." >&2
          exit 1
        fi
        # aws-account-id is now optional - will be auto-resolved if not provided

    - name: Prepare paths and env
      id: prepare-paths
      shell: bash
      run: |
        set -euo pipefail
        BACKEND_DIR="infrastructure/environment/${{ inputs.env }}/backend"
        mkdir -p "$BACKEND_DIR"
        CFG="$BACKEND_DIR/backend-config.json"
        echo "BACKEND_DIR=$BACKEND_DIR" >> "$GITHUB_ENV"
        echo "CFG=$CFG" >> "$GITHUB_ENV"
        echo "cfg=$CFG" >> "$GITHUB_OUTPUT"

    - name: Resolve AWS Account ID
      shell: bash
      run: |
        set -euo pipefail

        # Check if aws-account-id was provided as input
        if [[ -n "${{ inputs.aws-account-id }}" && "${{ inputs.aws-account-id }}" != "null" ]]; then
          AWS_ACCOUNT_ID="${{ inputs.aws-account-id }}"
          echo "Using provided AWS account ID: $AWS_ACCOUNT_ID"
        else
          echo "AWS account ID not provided, resolving from config files..."

          # Try to resolve from config files in order: local.yaml, globals.yaml, dictionary.yaml
          AWS_ACCOUNT_ID=""

          # Check local.yaml first
          if [[ -f "infrastructure/config/local.yaml" ]]; then
            echo "Checking local.yaml for AWS account ID..."
            # Try different key patterns
            for key in "aws_account_id" "account_id" "aws.account_id"; do
              if command -v yq >/dev/null 2>&1; then
                # Use yq if available
                value=$(yq eval ".$key" infrastructure/config/local.yaml 2>/dev/null || echo "")
              else
                # Fallback to grep/jq
                value=$(grep -E "^\s*$key\s*:" infrastructure/config/local.yaml | sed 's/.*:\s*//' | tr -d '"' | tr -d "'" || echo "")
              fi
              if [[ -n "$value" && "$value" != "null" ]]; then
                AWS_ACCOUNT_ID="$value"
                echo "Found AWS account ID in local.yaml: $AWS_ACCOUNT_ID"
                break
              fi
            done
          fi

          # Check globals.yaml if not found in local.yaml
          if [[ -z "$AWS_ACCOUNT_ID" && -f "infrastructure/config/globals.yaml" ]]; then
            echo "Checking globals.yaml for AWS account ID..."
            # Try different key patterns
            for key in "accounts.aws_account_id" "aws_account_id" "account_id" "aws.account_id"; do
              if command -v yq >/dev/null 2>&1; then
                # Use yq if available
                value=$(yq eval ".$key" infrastructure/config/globals.yaml 2>/dev/null || echo "")
              else
                # Fallback to grep/jq
                value=$(grep -E "^\s*$key\s*:" infrastructure/config/globals.yaml | sed 's/.*:\s*//' | tr -d '"' | tr -d "'" || echo "")
              fi
              if [[ -n "$value" && "$value" != "null" ]]; then
                AWS_ACCOUNT_ID="$value"
                echo "Found AWS account ID in globals.yaml: $AWS_ACCOUNT_ID"
                break
              fi
            done
          fi

          # Check dictionary.yaml if still not found
          if [[ -z "$AWS_ACCOUNT_ID" && -f "infrastructure/config/dictionary.yaml" ]]; then
            echo "Checking dictionary.yaml for AWS account ID..."
            # Try different key patterns
            for key in "aws_account_id" "account_id" "aws.account_id"; do
              if command -v yq >/dev/null 2>&1; then
                # Use yq if available
                value=$(yq eval ".$key" infrastructure/config/dictionary.yaml 2>/dev/null || echo "")
              else
                # Fallback to grep/jq
                value=$(grep -E "^\s*$key\s*:" infrastructure/config/dictionary.yaml | sed 's/.*:\s*//' | tr -d '"' | tr -d "'" || echo "")
              fi
              if [[ -n "$value" && "$value" != "null" ]]; then
                AWS_ACCOUNT_ID="$value"
                echo "Found AWS account ID in dictionary.yaml: $AWS_ACCOUNT_ID"
                break
              fi
            done
          fi

          # Validate that we found an account ID
          if [[ -z "$AWS_ACCOUNT_ID" ]]; then
            echo "ERROR: Could not resolve AWS account ID from config files." >&2
            echo "Please provide aws-account-id input or ensure it's set in one of:" >&2
            echo "  - infrastructure/config/local.yaml" >&2
            echo "  - infrastructure/config/globals.yaml" >&2
            echo "  - infrastructure/config/dictionary.yaml" >&2
            echo "Supported keys: aws_account_id, account_id, aws.account_id" >&2
            exit 1
          fi
        fi

        # Validate AWS account ID format (12 digits)
        if [[ ! "$AWS_ACCOUNT_ID" =~ ^[0-9]{12}$ ]]; then
          echo "ERROR: Invalid AWS account ID format: $AWS_ACCOUNT_ID" >&2
          echo "AWS account ID must be exactly 12 digits." >&2
          exit 1
        fi

        echo "Resolved AWS account ID: $AWS_ACCOUNT_ID"
        echo "AWS_ACCOUNT_ID=$AWS_ACCOUNT_ID" >> "$GITHUB_ENV"

    - name: Determine or generate bucket name
      id: determine-bucket
      shell: bash
      run: |
        set -euo pipefail
        : "${CFG:?CFG not set}"
        BUCKET=""
        if [[ -f "$CFG" ]]; then
          BUCKET="$(jq -r '.bucket // empty' "$CFG" 2>/dev/null || echo "")"
        fi
        if [[ -z "$BUCKET" ]]; then
          # Region short helper function
          region_short() {
            case "$1" in
              eu-west-1) echo "euw1" ;;
              eu-west-2) echo "euw2" ;;
              eu-west-3) echo "euw3" ;;
              eu-central-1) echo "euc1" ;;
              us-east-1) echo "use1" ;;
              us-east-2) echo "use2" ;;
              us-west-1) echo "usw1" ;;
              us-west-2) echo "usw2" ;;
              ap-south-1) echo "aps1" ;;
              *) echo "$1" ;;
            esac
          }

          # Stable bucket naming: <repo>-<project>-<env>-<function>-<account-id>-<region>
          REGION_SHORT="$(region_short "${{ inputs.aws-region }}")"
          CANDIDATE="${{ inputs.repo-shortname }}-${{ inputs.project }}-${{ inputs.env }}-${{ inputs.function }}-${AWS_ACCOUNT_ID}-${REGION_SHORT}"
          CANDIDATE="$(echo "$CANDIDATE" | tr '[:upper:]' '[:lower:]' | sed -E 's/[^a-z0-9-]+/-/g; s/-+/-/g; s/^-|-$//g')"

          # Deterministic bucket length guard with truncate+hash fallback
          if [[ ${#CANDIDATE} -le 63 ]]; then
            BUCKET="$CANDIDATE"
          else
            SUFFIX="$(printf '%s' "$CANDIDATE" | sha1sum | cut -c1-6)"
            TRIM=$((63 - 1 - 6))
            BUCKET="${CANDIDATE:0:$TRIM}-${SUFFIX}"
          fi
        fi
        echo "BUCKET=$BUCKET" >> "$GITHUB_ENV"
        echo "bucket=$BUCKET" >> "$GITHUB_OUTPUT"

    - name: Determine pipeline name and build key
      id: determine-pipeline
      shell: bash
      run: |
        set -euo pipefail
        : "${CFG:?CFG not set}"
        : "${BUCKET:?BUCKET not set}"

        # DynamoDB table name selection
        if [[ "${{ inputs.use-shared-lock-table }}" == "true" ]]; then
          if [[ -n "${{ inputs.lock-table-name }}" && "${{ inputs.lock-table-name }}" != "null" ]]; then
            # Use provided custom table name
            TABLE="${{ inputs.lock-table-name }}"
            echo "Using custom shared lock table: $TABLE"
          else
            # Derive shared table name from account/region using same logic as bucket
            region_short() {
              case "$1" in
                eu-west-1) echo "euw1" ;;
                eu-west-2) echo "euw2" ;;
                eu-west-3) echo "euw3" ;;
                eu-central-1) echo "euc1" ;;
                us-east-1) echo "use1" ;;
                us-east-2) echo "use2" ;;
                us-west-1) echo "usw1" ;;
                us-west-2) echo "usw2" ;;
                ap-south-1) echo "aps1" ;;
                *) echo "$1" ;;
              esac
            }
            aws_region_short="$(region_short "${{ inputs.aws-region }}")"
            TABLE="tfstate-locks-${AWS_ACCOUNT_ID}-${aws_region_short}"
            echo "Using derived shared lock table: $TABLE"
          fi
        else
          # Legacy behavior: per-bucket table
          TABLE="${BUCKET}-locks"
          echo "Using legacy per-bucket lock table: $TABLE"
        fi

        # Check if backend-config.json exists and read existing pipeline_name
        EXISTING_PIPELINE_NAME=""
        if [[ -f "$CFG" ]]; then
          EXISTING_PIPELINE_NAME=$(jq -r '.pipeline_name // empty' "$CFG" 2>/dev/null || echo "")
        fi

        # Determine pipeline_name
        PIPELINE_NAME_INPUT="${{ inputs.pipeline-name }}"
        if [[ -n "$EXISTING_PIPELINE_NAME" ]]; then
          # Reuse existing pipeline_name
          pipeline_name="$EXISTING_PIPELINE_NAME"
          echo "Reusing existing pipeline_name: $pipeline_name"
        elif [[ -n "${PIPELINE_NAME_INPUT}" && "${PIPELINE_NAME_INPUT}" != "null" ]]; then
          # Use provided pipeline_name
          pipeline_name="$PIPELINE_NAME_INPUT"
          echo "Using provided pipeline_name: $pipeline_name"
        else
          # Compute stable fallback with shorter format
          cloud_segment="${{ inputs.cloud-segment }}"
          if [[ -z "$cloud_segment" || "$cloud_segment" == "null" ]]; then cloud_segment="${{ inputs.cloud }}"; fi
          KEY_SALT="${{ inputs.key-salt }}"
          BASE="${GITHUB_REPOSITORY}|${{ inputs.env }}|${cloud_segment}|${{ inputs.app }}|${KEY_SALT}"

          # Extract repo name from GITHUB_REPOSITORY (org/repo -> repo)
          slug_repo="$(echo "$GITHUB_REPOSITORY" | cut -d'/' -f2 | tr '[:upper:]' '[:lower:]')"
          hash8="$(echo -n "$BASE" | sha1sum | cut -c1-8)"

          # Build pipeline_name with shorter format
          pipeline_name="tf-${slug_repo}-${{ inputs.env }}-${cloud_segment}-${{ inputs.app }}-${hash8}"

          # Normalize and truncate if needed
          pipeline_name="$(echo "$pipeline_name" | sed -E 's/[^a-z0-9-]+/-/g; s/-+/-/g; s/^-|-$//g')"
          if [[ ${#pipeline_name} -gt 63 ]]; then
            pipeline_name="${pipeline_name:0:63}"
          fi

          echo "Computed stable pipeline_name: $pipeline_name"
        fi

        # Build KEY using pipeline_name
        cloud_segment="${{ inputs.cloud-segment }}"
        if [[ -z "$cloud_segment" || "$cloud_segment" == "null" ]]; then cloud_segment="${{ inputs.cloud }}"; fi
        KEY="${{ inputs.repo-shortname }}/${{ inputs.project }}/${{ inputs.env }}/${cloud_segment}/${{ inputs.app }}/$pipeline_name.tfstate"

        # Safety check: prevent accidental state moves
        if [[ -f "$CFG" ]]; then
          EXISTING_KEY=$(jq -r '.key // empty' "$CFG" 2>/dev/null || echo "")
          if [[ -n "$EXISTING_KEY" && "$EXISTING_KEY" != "$KEY" ]]; then
            if [[ "${{ inputs.allow-key-mutation }}" != "true" ]]; then
              echo "ERROR: Refusing to change backend key from '$EXISTING_KEY' to '$KEY'. Set allow-key-mutation=true to override." >&2
              exit 1
            else
              echo "WARNING: Changing backend key from '$EXISTING_KEY' to '$KEY' (allow-key-mutation=true)"
            fi
          fi
        fi

        echo "TABLE=$TABLE" >> "$GITHUB_ENV"
        echo "KEY=$KEY" >> "$GITHUB_ENV"
        echo "PIPELINE_NAME=$pipeline_name" >> "$GITHUB_ENV"
        echo "table=$TABLE" >> "$GITHUB_OUTPUT"
        echo "key=$KEY" >> "$GITHUB_OUTPUT"

    - name: Write backend-config.json (early)
      shell: bash
      run: |
        set -euo pipefail
        : "${CFG:?CFG not set}"
        : "${BUCKET:?BUCKET not set}"
        : "${KEY:?KEY not set}"
        : "${TABLE:?TABLE not set}"
        : "${PIPELINE_NAME:?PIPELINE_NAME not set}"
        jq -n --arg bucket "$BUCKET" \
              --arg key "$KEY" \
              --arg region "${{ inputs.aws-region }}" \
              --arg table "$TABLE" \
              --arg pipeline_name "$PIPELINE_NAME" \
              '{bucket:$bucket, key:$key, region:$region, dynamodb_table:$table, pipeline_name:$pipeline_name}' > "$CFG"
        echo "Wrote early $CFG"
        cat "$CFG"

    - name: Ensure S3 bucket exists
      shell: bash
      run: |
        set -euo pipefail
        : "${BUCKET:?BUCKET not set}"
        set +e
        aws s3api head-bucket --bucket "$BUCKET" >/dev/null 2>&1
        EXISTS=$?
        set -e
        if [[ $EXISTS -ne 0 ]]; then
          if [[ "${{ inputs.aws-region }}" == "us-east-1" ]]; then
            aws s3api create-bucket --bucket "$BUCKET"
          else
            aws s3api create-bucket --bucket "$BUCKET" --region "${{ inputs.aws-region }}" \
              --create-bucket-configuration LocationConstraint="${{ inputs.aws-region }}"
          fi
        fi

    - name: Configure bucket (versioning, encryption, tags)
      shell: bash
      run: |
        set -euo pipefail
        : "${BUCKET:?BUCKET not set}"
        aws s3api put-bucket-versioning --bucket "$BUCKET" --versioning-configuration Status=Enabled
        aws s3api put-bucket-encryption --bucket "$BUCKET" --server-side-encryption-configuration '{
          "Rules":[{"ApplyServerSideEncryptionByDefault":{"SSEAlgorithm":"AES256"}}]
        }'
        # Tag bucket using jq to generate JSON file
        jq -n \
          --arg repo "${{ inputs.repo-shortname }}" \
          --arg project "${{ inputs.project }}" \
          --arg env "${{ inputs.env }}" \
          --arg app "${{ inputs.app }}" \
          --arg function "${{ inputs.function }}" \
          '{TagSet: [
            {Key: "Repo", Value: $repo},
            {Key: "Project", Value: $project},
            {Key: "Environment", Value: $env},
            {Key: "App", Value: $app},
            {Key: "Function", Value: $function}
          ]}' > tags.json
        echo "Applied tags: $(cat tags.json)"
        aws s3api put-bucket-tagging --bucket "$BUCKET" --tagging file://tags.json
        rm -f tags.json

    - name: Ensure DynamoDB lock table
      shell: bash
      run: |
        set -euo pipefail
        : "${TABLE:?TABLE not set}"
        set +e
        aws dynamodb describe-table --table-name "$TABLE" >/dev/null 2>&1
        EXISTS=$?
        set -e
        if [[ $EXISTS -ne 0 ]]; then
          aws dynamodb create-table \
            --table-name "$TABLE" \
            --attribute-definitions AttributeName=LockID,AttributeType=S \
            --key-schema AttributeName=LockID,KeyType=HASH \
            --billing-mode PAY_PER_REQUEST

          # Enable Point-in-Time Recovery if permissions allow (ignore failure)
          echo "Attempting to enable Point-in-Time Recovery for table: $TABLE"
          set +e
          aws dynamodb update-continuous-backups \
            --table-name "$TABLE" \
            --point-in-time-recovery-specification PointInTimeRecoveryEnabled=true
          if [[ $? -eq 0 ]]; then
            echo "✓ Point-in-Time Recovery enabled for $TABLE"
          else
            echo "⚠ Could not enable Point-in-Time Recovery for $TABLE (insufficient permissions or not supported)"
          fi
          set -e
        fi

    - name: Write backend-config.json
      shell: bash
      run: |
        set -euo pipefail
        : "${CFG:?CFG not set}"
        : "${BUCKET:?BUCKET not set}"
        : "${KEY:?KEY not set}"
        : "${TABLE:?TABLE not set}"
        : "${PIPELINE_NAME:?PIPELINE_NAME not set}"
        jq -n --arg bucket "$BUCKET" \
              --arg key "$KEY" \
              --arg region "${{ inputs.aws-region }}" \
              --arg table "$TABLE" \
              --arg pipeline_name "$PIPELINE_NAME" \
              '{bucket:$bucket, key:$key, region:$region, dynamodb_table:$table, pipeline_name:$pipeline_name}' > "$CFG"
        echo "Wrote $CFG"
        cat "$CFG"

    - name: Verify backend-config present
      shell: bash
      run: |
        set -euo pipefail
        : "${CFG:?CFG not set}"
        echo "Checking backend config at $CFG"
        test -f "$CFG"
        jq -C . "$CFG" || cat "$CFG"

    - name: Summary
      shell: bash
      run: |
        set -euo pipefail
        : "${BUCKET:?BUCKET not set}"
        : "${TABLE:?TABLE not set}"
        : "${KEY:?KEY not set}"
        : "${PIPELINE_NAME:?PIPELINE_NAME not set}"
        echo "Backend summary:"
        echo "BUCKET=$BUCKET"
        if [[ "${{ inputs.use-shared-lock-table }}" == "true" ]]; then
          echo "TABLE=$TABLE (SHARED)"
        else
          echo "TABLE=$TABLE (PER-BUCKET)"
        fi
        echo "KEY=$KEY"
        echo "PIPELINE_NAME=$PIPELINE_NAME"
        aws s3api get-bucket-versioning --bucket "$BUCKET" --query 'Status'
        aws s3api get-bucket-encryption --bucket "$BUCKET" \
          --query 'ServerSideEncryptionConfiguration.Rules[*].ApplyServerSideEncryptionByDefault.SSEAlgorithm'
        aws dynamodb describe-table --table-name "$TABLE" --query '{Status:Table.TableStatus,Key:Table.KeySchema}'