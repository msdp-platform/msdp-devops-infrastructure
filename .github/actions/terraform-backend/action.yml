name: "Terraform Backend (AWS)"
description: "Creates/ensures Terraform S3 state bucket and DynamoDB lock table, and writes backend-config.json."

inputs:
  repo-shortname:
    description: "Shortname of the repository (e.g., infra)"
    required: true
  project:
    description: "Project name (e.g., msdp)"
    required: true
  env:
    description: "Environment (e.g., dev, sit, prod)"
    required: true
  app:
    description: "Application/workload name (e.g., crossplane)"
    required: true
  function:
    description: "Function for bucket grouping (e.g., tfstate)"
    required: true
  pipeline-name:
    description: "Logical name for the pipeline or workflow using this backend (e.g., provisioner, addons, bootstrap)"
    required: true
  cloud-segment:
    description: "Cloud segment for key path (e.g., aws, azure)"
    required: true
  cloud:
    description: "Target cloud; only 'aws' is supported for now"
    required: true
  aws-account-id:
    description: "AWS account ID for backend uniqueness"
    required: true
  aws-region:
    description: "AWS region for the backend"
    required: false
    default: "eu-west-1"

runs:
  using: "composite"
  steps:
    - name: Validate inputs
      shell: bash
      run: |
        set -euo pipefail
        if [[ "${{ inputs.cloud }}" != "aws" ]]; then
          echo "ERROR: Only cloud=aws is supported at this time." >&2
          exit 1
        fi
        if [[ -z "${{ inputs.function }}" ]]; then
          echo "ERROR: function input is required and cannot be empty." >&2
          exit 1
        fi
        if [[ -z "${{ inputs.aws-account-id }}" ]]; then
          echo "ERROR: aws-account-id input is required and cannot be empty." >&2
          exit 1
        fi

    - name: Prepare paths and vars
      shell: bash
      run: |
        set -euo pipefail
        BACKEND_DIR="infrastructure/environment/${{ inputs.env }}/backend"
        mkdir -p "$BACKEND_DIR"
        echo "BACKEND_DIR=$BACKEND_DIR" >> "$GITHUB_ENV"
        echo "CFG=$BACKEND_DIR/backend-config.json" >> "$GITHUB_ENV"

        # Stable bucket naming: <repo>-<project>-<env>-<function>-<account-id>-<region>
        REGION_SHORT="$(echo "${{ inputs.aws-region }}" | sed 's/eu-west-/euw/;s/us-east-/use/;s/us-west-/usw/')"
        BUCKET="${{ inputs.repo-shortname }}-${{ inputs.project }}-${{ inputs.env }}-${{ inputs.function }}-${{ inputs.aws-account-id }}-${REGION_SHORT}"
        # Normalize to lowercase and safe chars
        BUCKET="$(echo "$BUCKET" | tr '[:upper:]' '[:lower:]' | sed -E 's/[^a-z0-9-]+/-/g')"

        # Basic length/syntax guard
        if [[ ${#BUCKET} -gt 63 ]]; then
          echo "ERROR: Bucket name too long: $BUCKET" >&2
          exit 1
        fi

        # DynamoDB table name
        TABLE="${BUCKET}-locks"

        # Compose key path with cloud segment and pipeline name
        KEY="${{ inputs.repo-shortname }}/${{ inputs.project }}/${{ inputs.env }}/${{ inputs.cloud-segment }}/${{ inputs.app }}/${{ inputs.pipeline-name }}.tfstate"

        echo "BUCKET=$BUCKET" >> "$GITHUB_ENV"
        echo "TABLE=$TABLE" >> "$GITHUB_ENV"
        echo "KEY=$KEY" >> "$GITHUB_ENV"

    - name: Ensure S3 bucket exists
      shell: bash
      run: |
        set -euo pipefail
        set +e
        aws s3api head-bucket --bucket "$BUCKET" >/dev/null 2>&1
        EXISTS=$?
        set -e
        if [[ $EXISTS -ne 0 ]]; then
          aws s3api create-bucket --bucket "$BUCKET" --region "${{ inputs.aws-region }}" \
            --create-bucket-configuration LocationConstraint="${{ inputs.aws-region }}"
        fi

    - name: Configure bucket (versioning, encryption, tags)
      shell: bash
      run: |
        set -euo pipefail
        aws s3api put-bucket-versioning --bucket "$BUCKET" --versioning-configuration Status=Enabled
        aws s3api put-bucket-encryption --bucket "$BUCKET" --server-side-encryption-configuration '{
          "Rules":[{"ApplyServerSideEncryptionByDefault":{"SSEAlgorithm":"AES256"}}]
        }'
        # Tag bucket using jq to generate JSON file
        jq -n \
          --arg repo "${{ inputs.repo-shortname }}" \
          --arg project "${{ inputs.project }}" \
          --arg env "${{ inputs.env }}" \
          --arg app "${{ inputs.app }}" \
          --arg function "${{ inputs.function }}" \
          '{TagSet: [
            {Key: "Repo", Value: $repo},
            {Key: "Project", Value: $project},
            {Key: "Environment", Value: $env},
            {Key: "App", Value: $app},
            {Key: "Function", Value: $function}
          ]}' > tags.json
        echo "Applied tags: $(cat tags.json)"
        aws s3api put-bucket-tagging --bucket "$BUCKET" --tagging file://tags.json
        rm -f tags.json

    - name: Ensure DynamoDB lock table
      shell: bash
      run: |
        set -euo pipefail
        set +e
        aws dynamodb describe-table --table-name "$TABLE" >/dev/null 2>&1
        EXISTS=$?
        set -e
        if [[ $EXISTS -ne 0 ]]; then
          aws dynamodb create-table \
            --table-name "$TABLE" \
            --attribute-definitions AttributeName=LockID,AttributeType=S \
            --key-schema AttributeName=LockID,KeyType=HASH \
            --billing-mode PAY_PER_REQUEST
        fi

    - name: Write backend-config.json
      shell: bash
      run: |
        set -euo pipefail
        jq -n --arg bucket "$BUCKET" \
              --arg key "$KEY" \
              --arg region "${{ inputs.aws-region }}" \
              --arg table "$TABLE" \
              '{bucket:$bucket, key:$key, region:$region, dynamodb_table:$table}' > "$CFG"
        echo "Wrote $CFG"
        cat "$CFG"

    - name: Summary
      shell: bash
      run: |
        set -euo pipefail
        echo "Backend summary:"
        echo "  Bucket: $BUCKET"
        aws s3api get-bucket-versioning --bucket "$BUCKET" --query 'Status'
        aws s3api get-bucket-encryption --bucket "$BUCKET" \
          --query 'ServerSideEncryptionConfiguration.Rules[*].ApplyServerSideEncryptionByDefault.SSEAlgorithm'
        echo "  Lock Table: $TABLE"
        aws dynamodb describe-table --table-name "$TABLE" --query '{Status:Table.TableStatus,Key:Table.KeySchema}'
